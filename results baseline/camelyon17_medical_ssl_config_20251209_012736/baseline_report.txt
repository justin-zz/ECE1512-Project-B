======================================================================
BASELINE EVALUATION REPORT
======================================================================

MODEL STRUCTURE AND COMPONENTS
----------------------------------------
Total parameters: 149,125
Trainable parameters: 149,125
Trainable ratio: 100.00%

Model Components:
  dimreduction: 49,152 params (33.0%)
  attention: 99,457 params (66.7%)
  classifier: 516 params (0.3%)

ARCHITECTURE DETAILS
----------------------------------------
Input feature dimension: 384
Number of classes: 4
Backbone: ViT-S/16
Pretraining: medical_ssl

TRAINING PROCEDURE
----------------------------------------
train_epochs: 50
batch_size: 1
learning_rate: 0.001
weight_decay: 5e-05
warmup_epochs: 1
min_learning_rate: 0
optimizer: AdamW
scheduler: Linear Warmup + Cosine Annealing
loss_function: CrossEntropyLoss
dataset: CAMELYON17
num_classes: 4
feature_dimension: 384

PERFORMANCE RESULTS
----------------------------------------
Best epoch: 19
Validation Accuracy: 86.6667
Validation AUC: 0.8582
Validation F1 Score: 0.7732
Test Accuracy: 82.0000
Test AUC: 0.8490
Test F1 Score: 0.5614

MODEL COMPONENT EXPLANATION
----------------------------------------
1. ENCODER (Feature Extractor):
   - Extracts features from individual image patches
   - Uses pre-trained Vision Transformer (ViT-S/16)
   - Converts images to feature vectors (384-dimensional)
   - Captures local texture and morphological patterns

2. AGGREGATOR (Attention Mechanism):
   - Weighs importance of different patches using attention
   - Identifies diagnostically relevant regions
   - Produces weighted sum of patch features
   - Handles variable number of patches per slide

3. CLASSIFIER (Prediction Layer):
   - Takes aggregated features as input
   - Maps to final class predictions (normal vs. tumor)
   - Typically fully connected layers with softmax
   - Outputs probability distribution over classes

======================================================================
